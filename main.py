import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

# -------------------------
# ãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆDecoderã®ã¿ï¼‰
# -------------------------
class Decoder(nn.Module):
    def __init__(self, latent_dim=3, num_classes=10):
        super().__init__()
        self.label_embedding = nn.Linear(num_classes, 16)
        self.fc_hidden = nn.Linear(latent_dim + 16, 128)
        self.fc_out = nn.Linear(128, 28 * 28)

    def forward(self, latent_vector, label):
        label_one_hot = F.one_hot(label, num_classes=10).float()
        label_embedding = F.relu(self.label_embedding(label_one_hot))
        x = torch.cat([latent_vector, label_embedding], dim=1)
        x = F.relu(self.fc_hidden(x))
        x = torch.sigmoid(self.fc_out(x))
        x = x.view(-1, 1, 28, 28)
        return x

# -------------------------
# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
# -------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------
# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
# -------------------------
decoder = Decoder(latent_dim=3)

# state_dictã®èª­ã¿è¾¼ã¿
state_dict = torch.load("cvae.pth", map_location=device)
# 'decoder.' ã§å§‹ã¾ã‚‹ã‚‚ã®ã ã‘æŠœãå‡ºã—ã¦ã‚­ãƒ¼åã‚‚ç›´ã™
decoder_state_dict = {k.replace("decoder.", ""): v for k, v in state_dict.items() if k.startswith("decoder.")}
# ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¢ãƒ‡ãƒ«ã¸ãƒ­ãƒ¼ãƒ‰
decoder.load_state_dict(decoder_state_dict)

decoder.to(device)
decoder.eval()

# -------------------------
# Streamlit UI
# -------------------------
st.title("ğŸ¨ æ¡ä»¶ä»˜ãç”»åƒç”Ÿæˆã‚¢ãƒ—ãƒªï¼ˆcVAEï¼‰")

# ãƒ©ãƒ™ãƒ«é¸æŠ
digit = st.selectbox("ç”Ÿæˆã—ãŸã„æ•°å­—ãƒ©ãƒ™ãƒ«", list(range(10)))

# æ½œåœ¨å¤‰æ•°ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼ˆz âˆˆ â„Â³ï¼‰
labels = ["z[0]ãŸã¶ã‚“ç·šã®å¤ªã•", "z[1]ãŸã¶ã‚“å¹…", "z[2]ãŸã¶ã‚“å›è»¢"]  # z[0], z[1], z[2] ã®æ„å‘³ã‚’ãƒ©ãƒ™ãƒ«åŒ–

z_values = []
for i, label in enumerate(labels):
    # å†…éƒ¨ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰ãˆãšã€è¡¨ç¤ºã ã‘æœ€å°é™å¤‰æ›´
    z_values.append(st.slider(label, -3.0, 3.0, 0.0, 0.1))



# ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›
z_tensor = torch.tensor(z_values, dtype=torch.float32).unsqueeze(0).to(device)
label_tensor = torch.tensor([digit], dtype=torch.long).to(device)

# æ¨è«–
with torch.no_grad():
    generated = decoder(z_tensor, label_tensor)

# ç”»åƒè¡¨ç¤º
image = generated[0][0].cpu().numpy()
st.image(image, width=200, clamp=True, caption=f"ç”Ÿæˆã•ã‚ŒãŸç”»åƒï¼ˆ{digit}ï¼‰")
